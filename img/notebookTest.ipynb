{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전이학습을 위한 이미지 특성 벡터 생성하는 모델 선택하기 \n",
    "handle_base_name = \"mobilenet_v2_tf2_pre_fv_v4\" # @param ['mobilenet_v2_tf2_pre_fv_v4', 'mobilenet_v2_140_224_v2', 'effNet_v2_1k_b0_fv_v2']\n",
    "\n",
    "#링크 \n",
    "handle_base_map = {\n",
    "  \"mobilenet_v2_tf2_pre_fv_v4\": \"https://www.kaggle.com/models/google/mobilenet-v2/frameworks/TensorFlow2/variations/tf2-preview-feature-vector/versions/4\",\n",
    "  \"mobilenet_v2_140_224_v2\": \"https://www.kaggle.com/models/google/mobilenet-v2/frameworks/TensorFlow2/variations/140-224-feature-vector/versions/2\",\n",
    "  \"effNet_v2_1k_b0_fv_v2\": \"https://www.kaggle.com/models/google/efficientnet-v2/frameworks/TensorFlow2/variations/imagenet1k-b0-feature-vector/versions/2\",\n",
    "}\n",
    "\n",
    "#인풋 이미지 사이즈 크기 \n",
    "handle_base_image_size_map = {\n",
    "  \"mobilenet_v2_tf2_pre_fv_v4\": 224,\n",
    "  \"mobilenet_v2_140_224_v2\": 224,\n",
    "  \"effNet_v2_1k_b0_fv_v2\": 224,\n",
    "}\n",
    "\n",
    "#아웃풋 FEATURE VECTOR SIZE \n",
    "handle_base_output_map ={\n",
    "  \"mobilenet_v2_tf2_pre_fv_v4\":1280,\n",
    "  \"mobilenet_v2_140_224_v2\": 1792,\n",
    "  \"effNet_v2_1k_b0_fv_v2\": 1280  \n",
    "    \n",
    "}\n",
    "\n",
    "model_handle = handle_base_map.get(handle_base_name)\n",
    "pixels = handle_base_image_size_map.get(handle_base_name, 224) #(2번째 파라미터는 해당 모델이 없을 시, 디폴트값\n",
    "feature_vector_size = handle_base_output_map.get(handle_base_name)\n",
    "\n",
    "print(f\"Selected model: {handle_base_name} : {model_handle}\")\n",
    "\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "print(f\"Input size {IMAGE_SIZE}, Output feature vector size {feature_vector_size}\")\n",
    "\n",
    "feature_extractor = hub.KerasLayer(\n",
    "    model_handle,\n",
    "    input_shape = IMAGE_SIZE +(3,),\n",
    "    output_shape = [feature_vector_size],\n",
    "    trainable = False\n",
    ")\n",
    "\n",
    "# 모델 선언\n",
    "model = tf.keras.Sequential([\n",
    "    feature_extractor,\n",
    "    tf.keras.layers.Dense(num_classes, activation ='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#\n",
    "# 말라리아 malaria\n",
    "#['parasitized', 'uninfected']\n",
    "#mobilenet-v2/frameworks/TensorFlow2/variations/tf2-preview-feature-vector/versions/4\n",
    "################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "###########전이학습을 위한 이미지 특성 벡터 생성하는 모델 선택하기########## \n",
    "handle_base_name = \"effNet_v2_1k_b0_fv_v2\" # @param ['mobilenet_v2_tf2_pre_fv_v4', 'mobilenet_v2_140_224_v2', 'effNet_v2_1k_b0_fv_v2']\n",
    "\n",
    "#링크 \n",
    "handle_base_map = {\n",
    "  \"mobilenet_v2_tf2_pre_fv_v4\": \"https://www.kaggle.com/models/google/mobilenet-v2/frameworks/TensorFlow2/variations/tf2-preview-feature-vector/versions/4\",\n",
    "  \"mobilenet_v2_140_224_v2\": \"https://www.kaggle.com/models/google/mobilenet-v2/frameworks/TensorFlow2/variations/140-224-feature-vector/versions/2\",\n",
    "  \"effNet_v2_1k_b0_fv_v2\": \"https://www.kaggle.com/models/google/efficientnet-v2/frameworks/TensorFlow2/variations/imagenet1k-b0-feature-vector/versions/2\",\n",
    "}\n",
    "\n",
    "#인풋 이미지 사이즈 크기 \n",
    "handle_base_image_size_map = {\n",
    "  \"mobilenet_v2_tf2_pre_fv_v4\": 224,\n",
    "  \"mobilenet_v2_140_224_v2\": 224,\n",
    "  \"effNet_v2_1k_b0_fv_v2\": 224,\n",
    "}\n",
    "\n",
    "#아웃풋 FEATURE VECTOR SIZE \n",
    "handle_base_output_map ={\n",
    "  \"mobilenet_v2_tf2_pre_fv_v4\":1280,\n",
    "  \"mobilenet_v2_140_224_v2\": 1792,\n",
    "  \"effNet_v2_1k_b0_fv_v2\": 1280  \n",
    "    \n",
    "}\n",
    "\n",
    "model_handle = handle_base_map.get(handle_base_name)\n",
    "pixels = handle_base_image_size_map.get(handle_base_name, 224) #(2번째 파라미터는 해당 모델이 없을 시, 디폴트값\n",
    "feature_vector_size = handle_base_output_map.get(handle_base_name)\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "\n",
    "print(f\"Selected model: {handle_base_name} : {model_handle}\")\n",
    "print(f\"Input size {IMAGE_SIZE}, Output feature vector size {feature_vector_size}\")\n",
    "\n",
    "feature_extractor = hub.KerasLayer(\n",
    "    model_handle,\n",
    "    input_shape = IMAGE_SIZE +(3,),\n",
    "    output_shape = [feature_vector_size],\n",
    "    trainable = False\n",
    ")\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "##########데이터세트 설정하기 (모델에 맞게 이미지 조정)##########\n",
    "\n",
    "#244x 244 사이즈로 리사이즈를 하고, 정규화를 해줍니다.\n",
    "def format_image(image,label):\n",
    "    image = tf.image.resize(image,(224,224))/255.0\n",
    "    return image, label\n",
    "\n",
    "#훈련, 검증, 테스트 세트로 나눕니다.\n",
    "(raw_train, raw_validation, raw_test), metadata =tfds.load(\n",
    "    'malaria',\n",
    "    split=['train[:80%]','train[80%:90%]','train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "\n",
    "print(metadata)\n",
    "\n",
    "num_examples = metadata.splits['train'].num_examples\n",
    "num_classes = metadata.features['label'].num_classes\n",
    "class_names =metadata.features['label'].names\n",
    "print(class_names)\n",
    "\n",
    "#train data 대표 이미지 9개 보여주기 \n",
    "fig = tfds.show_examples(raw_train, metadata)\n",
    "\n",
    "train_batches = raw_train.shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "validation_batches = raw_validation.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "test_batches = raw_test.map(format_image).batch(1)\n",
    "\n",
    "##########모델 정의하기#############\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    feature_extractor,\n",
    "    tf.keras.layers.Dense(num_classes, activation ='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss ='sparse_categorical_crossentropy',\n",
    "    metrics =['accuracy']\n",
    ")\n",
    "\n",
    "hist = model.fit(\n",
    "    train_batches,\n",
    "    epochs = 5,\n",
    "    validation_data = validation_batches\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#트레이닝 결과 그래프 보여주기 \n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss (training and validation)\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(hist[\"loss\"])\n",
    "plt.plot(hist[\"val_loss\"])\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Accuracy (training and validation)\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(hist[\"accuracy\"])\n",
    "plt.plot(hist[\"val_accuracy\"])\n",
    "\n",
    "#학습된 모델 saved_model로 저장하기 \n",
    "_SAVED_MODEL = \"/content/drive/MyDrive/INTEL_PYTHON/malaria_saved_model\"\n",
    "tf.saved_model.save(model, _SAVED_MODEL)\n",
    "\n",
    "# tensoflow Lite 파일 생성하기 \n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(_SAVED_MODEL)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT] #Dynamic Range Quantization\n",
    "tflite_model = converter.convert()\n",
    "tflite_model_file = '/content/drive/MyDrive/INTEL_PYTHON/malaria_converted_model.tflite'\n",
    "\n",
    "#with open(…) as f 에서 f는 open(…)함수가 리턴한 file object.\n",
    "with open(tflite_model_file, \"wb\") as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "\n",
    "###########################\n",
    "## 라즈베리 파이에서 실행할 추론 코드 \n",
    "###########################\n",
    "\n",
    "#인터프리터 생성 \n",
    "interpreter = tflite.Interpreter(model_path='/content/drive/MyDrive/INTEL_PYTHON/malaria_converted_model.tflite')\n",
    "\n",
    "#텐서 할당\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "print('input: ', input_details)\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "print('output: ', output_details)\n",
    "\n",
    "\n",
    "\n",
    "predictions =[]\n",
    "\n",
    "print(input_index)\n",
    "print(output_index)\n",
    "\n",
    "#추론하기 \n",
    "predictions =[]\n",
    "test_labels, test_imgs = [],[]\n",
    "for img, label in test_batches.take(100):\n",
    "    interpreter.set_tensor(input_index, img)\n",
    "    interpreter.invoke()\n",
    "    predictions.append(interpreter.get_tensor(output_index))\n",
    "    test_labels.append(label.numpy()[0])\n",
    "    test_imgs.append(img)\n",
    "\n",
    "\n",
    "#추론 결과 점수로 확인하기 \n",
    "score  = 0\n",
    "for item in range(0,100):\n",
    "    prediction = np.argmax(predictions[item])\n",
    "    label = test_labels[item]\n",
    "    if prediction == label:\n",
    "        score = score +1\n",
    "\n",
    "print(\"100개 중 맞은 예측 수: \"+ str(score))\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    true_label, img = true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    img = tf.squeeze(img) \n",
    "    plt.imshow(img)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array[index])\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                    100*np.max(predictions_array),\n",
    "                                    class_names[true_label]),\n",
    "                                    color=color)\n",
    "\n",
    "\n",
    "for index in range(0,30):\n",
    "\n",
    "    if index%2 == 0 :\n",
    "      plt.figure(figsize = (6,3))\n",
    "      plt.subplot(121)\n",
    "    elif index %2 ==1 :\n",
    "      plt.subplot(122)\n",
    "\n",
    "    plot_image(index, predictions, test_labels, test_imgs)\n",
    "    if index %2 ==1:\n",
    "      plt.show()\n",
    "      #imgFile = 'resultImg/result{}.png'.format(index)\n",
    "      #plt.savefig(imgFile)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
